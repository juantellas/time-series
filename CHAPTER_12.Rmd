---
title: "MODELOS PREDICTIVOS (SECCION 12)"
output: html_document
date: "2024-04-29"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# CHAPTER 12: Forecasting with Machile Learning Models

## I: Forecasting monthly vehicle sales in the US - a case study

### 1: Exploratory analysis of the USVSales series

#### a)

```{r}
library(TSstudio)

data(USVSales)
```

#### b): The series structure

```{r}
ts_info(USVSales)
```   

```{r}
ts_plot(USVSales,
        title = "US Total Monthly Vehicle Sales",
        Ytitle = "Thousands of Units",
        Xtitle = "Year")
```


#### c): The series components

```{r}
ts_decompose(USVSales)
```

#### d): Seasonal analysis

```{r}
USVSales_detrend <- USVSales - decompose(USVSales)$trend

ts_seasonal(USVSales_detrend, type = "box")
```

#### e): Correlation analysis

```{r}
library(h20)
library(TSstudio)
library(plotly)
library(lubridate)
#ts_acf(USVSales)
```

```{r}
ts_lags(USVSales, lags = c(12, 24, 36))
```

#### f): Exploratory analysis - key findings


```{r}
# df <- ts_to_prophet(window(USVSales, start = c(2010,1))) %>% 
# 
# names(df) <- c("date", "y")
# 
# head(df)
```

```{r}
# ts_plot(df,
#         title = "US Total Monthly Vehicle Sales (Subset)",
#         Ytitle = "Thousands of Units",
#         Xtitle = "Year")
```

## II: Feature Engineering

### 1: Training, testing and model evaluation

#### a)

```{r}
library(dplyr)
library(lubridate)

df <- df %>% mutate(month = factor(lubridate::month(date, label = TRUE), ordered = FALSE),
                    lag12 = lag(y, n = 12)) %>%
  filter(!is.na(lag12))
```

```{r}
df$trend <- 1:nrow(df)
df$trend_sqr <- df$trend ^ 2

str(df)
```

```{r}
h <- 12
train_df <- df[1:(nrow(df) - h), ]
test_df <- df[(nrow(df) - h + 1):nrow(df), ]
```

#### b)

```{r}
forecast_df <- data.frame(date = seq.Date(from = max(df$date) + lubridate::month(1),
                                          length.out = h, by = "month"),
                          trend = seq(from = max(df$trend) + 1, length.out = h, by = 1))
forecast_df$trend_sqr <- forecast_df$trend ^ 2

# to avoid conflict with the h2o `month` function use the "lubridate::month" to explicly call the month from the lubridate function 
forecast_df$month <- factor(lubridate::month(forecast_df$date, label = TRUE), ordered= FALSE) 
forecast_df$lag12 <- tail(df$y, 12)

```

### 2: Model benchmark

#### a)

```{r}
lr <- lm(y ~ month + lag12 + trend + trend_sqr, data = train_df)
```

```{r}
summary(lr)
```

```{r}
test_df$yhat <- predict(lr, newdata = test_df)

mape_lr <- mean(abs(test_df$y - test_df$yhat) / test_df$y)
mape_lr
```


### 3: Starting a h2o cluster

#### a)

```{r}
# library(h2o)
# 
# h2o.init()
# h2o.init(max_mem_size = "16G")

```

```{r}
# train_h <- as.h2o(train_df)
# test_h <- as.h2o(test_df)
# forecast_h <- as.h2o(forecast_df)
```

```{r}
x <- c("month", "lag12", "trend", "trend_sqr")
y <- "y"
```

## III: Forecasting with the Random Forest model

### 1

```{r}
# rf_md <- h2o.randomForest(training_frame = train_h,
#                           nfolds = 5,
#                           x = x,
#                           y = y,
#                           ntrees = 500,
#                           stopping_rounds = 10,
#                           stopping_metric = "RMSE",
#                           score_each_iteration = TRUE,
#                           stopping_tolerance = 0.0001,
#                           seed = 1234)
```

```{r}
#h2o.varimp_plot(rf_md)
```

```{r}
#rf_md@model$model_summary
```

### 2

```{r}
# library(plotly)
# 
# tree_score <- rf_md@model$scoring_history$training_rmse
# plot_ly(x = seq_along(tree_score), y = tree_score,
#         type = "scatter", mode = "line") %>%
#   layout(title = "Random Forest Model - Trained Score History",
#          yaxis = list(title = "RMSE"),
#          xaxis = list(title = "Num. of Trees"))
```

```{r}
# test_h$pred_rf <- h2o.predict(rf_md, test_h)
# 
# test_1 <- as.data.frame(test_h)
# 
# mape_rf <- mean(abs(test_1$y - test_1$pred_rf) / test_1$y)
# mape_rf
```

```{r}
# search_criteria_rf <- list(
#   strategy = "RandomDiscrete",
#   stopping_metric = "rmse",
#   stopping_tolerance = 0.0001,
#   stopping_rounds = 10,
#   max_runtime_secs = 60 * 20
# )
# 
# hyper_params_rf <- list(mtries = c(2, 3, 4),
#                         sample_rate = c(0.632, 0.8, 0.95),
#                         col_sample_rate_per_tree = c(0.5, 0.9, 1.0),
#                         max_depth = c(seq(1, 30, 3)),
#                         min_rows = c(1, 2, 5, 10))
# 
# search_criteria_rf <- list(strategy = "RandomDiscrete",
#                            stopping_metric = "rmse",
#                            stopping_tolerance = 0.0001,
#                            stopping_rounds = 10,
#                            max_runtime_secs = 60 * 20)
# 
# rf2 <- h2o.grid(algorithm = "randomForest",
#                 search_criteria = search_criteria_rf,
#                 hyper_params = hyper_params_rf,
#                 x = x,
#                 y = y,
#                 training_frame = train_h,
#                 ntrees = 5000,
#                 nfolds = 5,
#                 grid_id = "rf_grid",
#                 seed = 1234)
# 
# ```
# 
# ```{r}
# rf2_grid_search <- h2o.getGrid(grid_id = "rf_grid",
#                                sort_by = "rmse",
#                                decreasing = FALSE)
# 
# rf_grid_model <- h2o.getModel(rf2_grid_search@model_ids[[1]])
# 
# 
# test_h$rf_grid  <- h2o.predict(rf_grid_model, test_h)
# mape_rf2 <- mean(abs(test_1$y - test_1$rf_grid) / test_1$y)
# mape_rf2
```


### 3

```{r}
# plot_ly(data = test_1) %>%
#   add_lines(x = ~ date, y = ~y, name = "Actual") %>%
#   add_lines(x = ~ date, y = ~ yhat, name = "Linear Regression", line = list(dash = "dot")) %>%
#   add_lines(x = ~ date, y = ~ pred_rf, name = "Random Forest", line = list(dash = "dash")) %>%
#   add_lines(x = ~ date, y = ~ rf_grid, name = "Random Forest (grid)", line = list(dash = "dash")) %>%
#   layout(title = "Total Vehicle Sales - Actual vs. Prediction (Random Forest)",
#          yaxis = list(title = "Thousands of Units"),
#          xaxis = list(title = "Month"))
```

## IV: Forecasting with the GBM model

### 1

```{r}
# gbm_md <- h2o.gbm(
#   training_frame = train_h,
#   nfolds = 5,
#   x = x,
#   y = y,
#   max_depth = 20,
#   distribution = "gaussian",
#   ntrees = 500,
#   learn_rate = 0.1,
#   score_each_iteration = TRUE
# )

```

```{r}
# h2o.varimp_plot(gbm_md)
# 
# test_h$pred_gbm  <- h2o.predict(gbm_md, test_h)
# test_1 <- as.data.frame(test_h)
# 
# mape_gbm <- mean(abs(test_1$y - test_1$pred_gbm) / test_1$y)
# mape_gbm
```

### 2

```{r}
# plot_ly(data = test_1) %>%
#   add_lines(x = ~ date, y = ~y, name = "Actual") %>%
#   add_lines(x = ~ date, y = ~ yhat, name = "Linear Regression", line = list(dash = "dot")) %>%
#   add_lines(x = ~ date, y = ~ pred_gbm, name = "Gradient Boosting Machine", line = list(dash = "dash")) %>%
#   layout(title = "Total Vehicle Sales - Actual vs. Prediction (Gradient Boosting Machine)",
#          yaxis = list(title = "Thousands of Units"),
#          xaxis = list(title = "Month"))
```

## V: Forecasting with the AutoML model

### 1

```{r}
# autoML1 <- h2o.automl(training_frame = train_h,
#                       x = x,
#                       y = y,
#                       nfolds = 5,
#                       max_runtime_secs = 60*20,
#                       seed = 1234)
```

```{r}
# autoML1@leaderboard
# 
# test_h$pred_autoML  <- h2o.predict(autoML1@leader, test_h)
# test_1 <- as.data.frame(test_h)
# 
# mape_autoML <- mean(abs(test_1$y - test_1$pred_autoML) / test_1$y)
# mape_autoML
```

### 2

```{r}
# plot_ly(data = test_1) %>%
#   add_lines(x = ~ date, y = ~y, name = "Actual") %>%
#   add_lines(x = ~ date, y = ~ yhat, name = "Linear Regression", line = list(dash = "dot")) %>%
#   add_lines(x = ~ date, y = ~ pred_autoML, name = "autoML", line = list(dash = "dash")) %>%
#   layout(title = "Total Vehicle Sales - Actual vs. Prediction (Auto ML Model)",
#          yaxis = list(title = "Thousands of Units"),
#          xaxis = list(title = "Month"))
```

## VI: Selecting the final model

### 1

```{r}
# forecast_h$pred_gbm  <- h2o.predict(gbm_md, forecast_h)
# forecast_h$pred_rf  <- h2o.predict(rf_grid_model, forecast_h)
# forecast_h$pred_automl  <- h2o.predict(autoML1@leader, forecast_h)
# 
# final_forecast <- as.data.frame(forecast_h)
# 
# plot_ly(x = df$date, y = df$y,
#         type = "scatter",
#         mode = "line", 
#         name = "Actual") %>% 
#   add_lines(x = final_forecast$date, y = final_forecast$pred_rf, name = "Random Forest") %>%
#   add_lines(x = final_forecast$date, y = final_forecast$pred_gbm, name = "GBM") %>%
#   add_lines(x = final_forecast$date, y = final_forecast$pred_automl, name = "Auto ML") %>%
#   layout(title = "Total Vehicle Sales - Final Forecast",
#          yaxis = list(title = "Thousands of Units", range = c(1100, 1750)),
#          xaxis = list(title = "Month", range = c(as.Date("2016-01-01"), as.Date("2020-01-01"))))
```

